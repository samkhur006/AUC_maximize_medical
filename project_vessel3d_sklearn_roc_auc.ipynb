{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBdF4GG-9Il8",
        "outputId": "cb103693-6eea-4f71-d97a-f6ba6827857b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting libauc==1.2.0\n",
            "  Downloading libauc-1.2.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.5.3)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (4.7.0.72)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (0.19.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (8.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.12.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (2.0.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.1.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2->libauc==1.2.0) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2->libauc==1.2.0) (3.25.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc==1.2.0) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (1.10.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (2023.4.12)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (23.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc==1.2.0) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->libauc==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.2->libauc==1.2.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2->libauc==1.2.0) (1.3.0)\n",
            "Installing collected packages: libauc\n",
            "Successfully installed libauc-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-2.2.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (8.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.65.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.0.0+cu118)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.22.4)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.15.1+cu118)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2022.7.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.4.12)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.10.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.12.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.11.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.5.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (16.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2022.12.7)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=ed47ddc13bb414ea12539189a6fc18ec38e47c0d216172b306254712af291bf0\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install libauc==1.2.0\n",
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gbqX-H869ab2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37c7f3fa-f824-4afc-d5ea-9497edf781e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-594cb2bb91d2>:18: DeprecationWarning: Please use `gaussian_filter` from the `scipy.ndimage` namespace, the `scipy.ndimage.filters` namespace is deprecated.\n",
            "  from scipy.ndimage.filters import gaussian_filter\n"
          ]
        }
      ],
      "source": [
        "import libauc;\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from medmnist import VesselMNIST3D\n",
        "\n",
        "from libauc.models import resnet18\n",
        "from libauc.losses import AUCMLoss, CrossEntropyLoss\n",
        "from libauc.optimizers import PESG, Adam\n",
        "from libauc.utils import ImbalancedDataGenerator\n",
        "from libauc.sampler import DualSampler  # data resampling (for binary class)\n",
        "from libauc.metrics import auc_roc_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import random\n",
        "import scipy\n",
        "from scipy.ndimage import rotate\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "SEED=123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IPvcQiVZ1s19"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "Adapted from kuangliu/pytorch-cifar .\n",
        "'''\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        # self.bn1 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
        "        \n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        # self.bn2 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "                # nn.GroupNorm(num_groups=2, num_channels=self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        # self.bn1 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        # self.bn2 = nn.GroupNorm(num_groups=2, num_channels=planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "        # self.bn3 = nn.GroupNorm(num_groups=2, num_channels=self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "                # nn.GroupNorm(num_groups=2, num_channels=self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, in_channels=1, num_classes=2):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        # self.bn1 = nn.GroupNorm(num_groups=2, num_channels=64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "        self.linear = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        # out = F.avg_pool2d(out, 4)\n",
        "        # out = F.adaptive_avg_pool3d(out, output_size=4)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(in_channels, num_classes):\n",
        "    return ResNet(BasicBlock, [2, 2, 2, 2], in_channels=in_channels, num_classes=num_classes)\n",
        "\n",
        "\n",
        "def ResNet50(in_channels, num_classes):\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3], in_channels=in_channels, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS9RSC169wC6",
        "outputId": "a3b4dcd1-9211-4fef-99ec-ca7f36745641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/vesselmnist3d.npz?download=1 to /root/.medmnist/vesselmnist3d.npz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 398373/398373 [00:01<00:00, 300186.87it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/vesselmnist3d.npz\n",
            "Using downloaded and verified file: /root/.medmnist/vesselmnist3d.npz\n"
          ]
        }
      ],
      "source": [
        "train_npz=VesselMNIST3D(split=\"train\", download=True)\n",
        "val_npz=VesselMNIST3D(split=\"val\", download=True)\n",
        "test_npz=VesselMNIST3D(split=\"test\", download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni9_kZPEy3ET",
        "outputId": "4c564009-e0d1-4807-bd07-9649e6fbdfba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset VesselMNIST3D (vesselmnist3d)\n",
              "    Number of datapoints: 1335\n",
              "    Root location: /root/.medmnist\n",
              "    Split: train\n",
              "    Task: binary-class\n",
              "    Number of channels: 1\n",
              "    Meaning of labels: {'0': 'vessel', '1': 'aneurysm'}\n",
              "    Number of samples: {'train': 1335, 'val': 192, 'test': 382}\n",
              "    Description: The VesselMNIST3D is based on an open-access 3D intracranial aneurysm dataset, IntrA, containing 103 3D models (meshes) of entire brain vessels collected by reconstructing MRA images. 1,694 healthy vessel segments and 215 aneurysm segments are generated automatically from the complete models. We fix the non-watertight mesh with PyMeshFix and voxelize the watertight mesh with trimesh into 28×28×28 voxels. We split the source dataset with a ratio of 7:1:2 into training, validation and test set.\n",
              "    License: CC BY 4.0"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_npz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "DIur0t5KBGnI"
      },
      "outputs": [],
      "source": [
        "def gaussian_blur_3d(img):\n",
        "    random.seed(SEED)\n",
        "    sigma = random.uniform(0.1,0.9)\n",
        "    blurred = gaussian_filter(img, sigma=sigma)\n",
        "    return blurred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M6Etf16IBNVx"
      },
      "outputs": [],
      "source": [
        "def x_flip(img):\n",
        "    random.seed(SEED)\n",
        "    flipped = img[:, :, ::-1]\n",
        "    return flipped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "miD1eOA8BVoZ"
      },
      "outputs": [],
      "source": [
        "def y_flip(img):\n",
        "    random.seed(SEED)\n",
        "    flipped = img[:, ::-1, :]\n",
        "    return flipped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zU1FgZEGBhdP"
      },
      "outputs": [],
      "source": [
        "def zoom_xy(img, min_zoom, max_zoom):\n",
        "    random.seed(SEED)\n",
        "    zoom_factor = random.uniform(min_zoom, max_zoom)\n",
        "    h, w = img.shape[0], img.shape[1]\n",
        "\n",
        "    # For multichannel images we don't want to apply the zoom factor to the RGB\n",
        "    # dimension, so instead we create a tuple of zoom factors, one per array\n",
        "    # dimension, with 1's for any trailing dimensions after the width and height.\n",
        "    zoom_tuple = (1, zoom_factor, zoom_factor)\n",
        "\n",
        "    # Zooming out\n",
        "    if zoom_factor < 1:\n",
        "\n",
        "        # Bounding box of the zoomed-out image within the output array\n",
        "        zh = int(np.round(h * zoom_factor))\n",
        "        zw = int(np.round(w * zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        # Zero-padding\n",
        "        out = np.zeros_like(img)\n",
        "        zoomed_img = zoom(img, zoom_tuple, order=0)\n",
        "        #print(f\"zoomed shape: {zoomed_img.shape}\")\n",
        "        #print(f\"out shape:{out.shape}\")\n",
        "        #print(f\"w:{w},h:{h},l:{left},t:{top},zw:{zw}, zh:{zh}\")\n",
        "        out[:, top:top+zh, left:left+zw] = zoomed_img\n",
        "\n",
        "    # Zooming in\n",
        "    elif zoom_factor > 1:\n",
        "\n",
        "        # Bounding box of the zoomed-in region within the input array\n",
        "        zh = int(np.ceil(h / zoom_factor))\n",
        "        zw = int(np.ceil(w / zoom_factor))\n",
        "        top = (h - zh) // 2\n",
        "        left = (w - zw) // 2\n",
        "\n",
        "        #out_template = np.zeros_like(img)\n",
        "        out = zoom(img[:, top:top+zh, left:left+zw], zoom_tuple, order=0)\n",
        "        #print(f\"out shape:{out.shape}\")\n",
        "        #print(f\"w:{w},h:{h},l:{left},t:{top},zw:{zw}, zh:{zh}\")\n",
        "\n",
        "        # `out` might still be slightly larger than `img` due to rounding, so\n",
        "        # trim off any extra pixels at the edges\n",
        "        trim_top = ((out.shape[1] - h) // 2)\n",
        "        trim_left = ((out.shape[2] - w) // 2)\n",
        "        #print(f\"out shape before:{out.shape}\")\n",
        "        out = out[:, trim_top:trim_top+h, trim_left:trim_left+w]\n",
        "        #print(f\"out shape after:{out.shape}\")\n",
        "        #print(f\"w:{w},h:{h},l:{left},trimtop:{trim_top},trimleft:{trim_left}\")\n",
        "\n",
        "    # If zoom_factor == 1, just return the input array\n",
        "    else:\n",
        "        out = img\n",
        "    #print(out.shape)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iCmxju1gSN9q"
      },
      "outputs": [],
      "source": [
        "def random_rotation_3d(img, min_angle, max_angle):\n",
        "    \"\"\" Randomly rotate an image by a random angle (-max_angle, max_angle).\n",
        "\n",
        "    Arguments:\n",
        "    max_angle: `float`. The maximum rotation angle.\n",
        "\n",
        "    Returns:\n",
        "    rotated 3D image\n",
        "    \"\"\"\n",
        "    random.seed(SEED)\n",
        "    img_rot = np.zeros(img.shape)\n",
        "    angle = random.uniform(min_angle, max_angle)\n",
        "    if random.randint(1,100) > 50:\n",
        "        #in half the cases, rotate left. in other half, rotate right.\n",
        "        angle *= -1\n",
        "        # Following lines would rotate on z and y axis as well, but not using them in this kernel\n",
        "#        # rotate along z-axis\n",
        "#        image2 = scipy.ndimage.interpolation.rotate(image1, angle, mode='nearest', axes=(0, 1), reshape=False)\n",
        "#        # rotate along y-axis\n",
        "#        image3 = scipy.ndimage.interpolation.rotate(image2, angle, mode='nearest', axes=(0, 2), reshape=False)\n",
        "\n",
        "    # rotate along x-axis\n",
        "    img_rot = scipy.ndimage.interpolation.rotate(img, angle, mode='nearest', axes=(1, 2), reshape=False)\n",
        "    return img_rot.reshape(img.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JMM1rAUoC2fb"
      },
      "outputs": [],
      "source": [
        "def img_augment_3d(X_train,y_train):\n",
        "      my_img=X_train\n",
        "      my_label=y_train\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = gaussian_blur_3d(img)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "      print(\"done\")\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = x_flip(img)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "      print(\"done\")\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = y_flip(img)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = random_rotation_3d(img, 1, 10)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = zoom_xy(img, 0.9, 1.1)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "    \n",
        "      return my_img,my_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "VjbjEHBL9zDi"
      },
      "outputs": [],
      "source": [
        "X_train=train_npz.imgs\n",
        "y_train=train_npz.labels\n",
        "\n",
        "X_val=val_npz.imgs\n",
        "y_val=val_npz.labels\n",
        "\n",
        "X_test=test_npz.imgs\n",
        "y_test=test_npz.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-4BvvFXTk6m",
        "outputId": "0f85a81e-bc70-4f11-d628-448414afe879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1335, 28, 28, 28)\n",
            "(1335, 1)\n",
            "(192, 28, 28, 28)\n",
            "(192, 1)\n",
            "(382, 28, 28, 28)\n",
            "(382, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "bo7RmNb8T-kM"
      },
      "outputs": [],
      "source": [
        "# X_train,y_train=img_augment_3d(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "FXKk7jbUaK_k"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, image_size=28, crop_size=26, mode='train'):\n",
        "       self.images = images.astype(np.uint8)\n",
        "       self.targets = targets\n",
        "       self.mode = mode\n",
        "       self.transform_train = transforms.Compose([                                               \n",
        "                              transforms.ToTensor(),\n",
        "                              # transforms.RandomCrop((crop_size, crop_size, crop_), padding=None),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              # transforms.Resize((image_size, image_size, image_size)),\n",
        "                              ])\n",
        "       self.transform_test = transforms.Compose([\n",
        "                             transforms.ToTensor(),\n",
        "                            #  transforms.Resize((image_size, image_size, image_size)),\n",
        "                              ])\n",
        "       \n",
        "       # for loss function\n",
        "       self.pos_indices = np.flatnonzero(targets==1)\n",
        "       self.pos_index_map = {}\n",
        "       for i, idx in enumerate(self.pos_indices):\n",
        "           self.pos_index_map[idx] = i\n",
        "\n",
        "    def __len__(self):\n",
        "        # print(len(self.images))\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        # print(\"GetItem enter: {}\".format(image.shape))\n",
        "        # print(\"hello12\")\n",
        "        target = self.targets[idx]\n",
        "        # image = Image.fromarray(image.astype('uint8'))\n",
        "        # image = Image.fromarray(image.squeeze(), mode='L')\n",
        "        # print(\"Image shape: {}\".format(image.shape))\n",
        "        # image = Image.fromarray(image.squeeze().astype('uint8'), mode='L')\n",
        "        if self.mode == 'train':\n",
        "            idx = self.pos_index_map[idx] if idx in self.pos_indices else -1\n",
        "            image = self.transform_train(image)\n",
        "            # print(type(image))\n",
        "        else:\n",
        "            image = self.transform_test(image)\n",
        "            # print(type(image))\n",
        "        return image, target, int(idx)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "paXm1nfPBE_d"
      },
      "outputs": [],
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ebSFQuU9BIoC"
      },
      "outputs": [],
      "source": [
        "\n",
        "# HyperParameters\n",
        "SEED = 123\n",
        "batch_size = 64\n",
        "total_epochs = 80\n",
        "decay_epochs = [50, 75]\n",
        "\n",
        "lr = 0.07\n",
        "margin = 1.0\n",
        "epoch_decay = 0.003 # refers gamma in the paper\n",
        "weight_decay = 0.0001\n",
        "\n",
        "# oversampling minority class, you can tune it in (0, 0.5]\n",
        "# e.g., sampling_rate=0.2 is that num of positive samples in mini-batch is sampling_rate*batch_size=13\n",
        "sampling_rate = 0.2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-MhjgR2SEmgE",
        "outputId": "3532c03d-7d20-49c5-b775-2e01b48dfb70"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#SAMPLES: [1335], POS:NEG: [150 : 1185], POS RATIO: 0.1124\n",
            "#SAMPLES: [192], POS:NEG: [22 : 170], POS RATIO: 0.1146\n",
            "#SAMPLES: [382], POS:NEG: [43 : 339], POS RATIO: 0.1126\n",
            "(1335, 28, 28, 28)\n",
            "(192, 28, 28, 28)\n",
            "(382, 28, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "imratio = 0.3\n",
        "generator = ImbalancedDataGenerator(shuffle=True, verbose=True, random_seed=0)\n",
        "\n",
        "(train_images, train_labels) = generator.transform(X_train, y_train, imratio=imratio)\n",
        "(eval_images, eval_labels) = generator.transform(X_val, y_val, imratio=imratio)\n",
        "(test_images, test_labels) = generator.transform(X_test, y_test, imratio=0.5) \n",
        "\n",
        "print((train_images.shape))\n",
        "print((eval_images.shape))\n",
        "print((test_images.shape))\n",
        "trainSet = ImageDataset(train_images, train_labels)\n",
        "evalSet = ImageDataset(eval_images, eval_labels)\n",
        "testSet = ImageDataset(test_images, test_labels, mode='test')\n",
        "\n",
        "sampler = DualSampler(trainSet, batch_size, sampling_rate=sampling_rate)\n",
        "trainloader = torch.utils.data.DataLoader(trainSet, batch_size=batch_size,  sampler=sampler,  shuffle=False,  num_workers=1)\n",
        "evalloader = torch.utils.data.DataLoader(evalSet, batch_size=batch_size,  shuffle=False,  num_workers=1)\n",
        "testloader = torch.utils.data.DataLoader(testSet , batch_size=batch_size, shuffle=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kLN4Unkc9_A0"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# model\n",
        "set_all_seeds(SEED)\n",
        "# model = resnet18(pretrained=False, num_classes=1, last_activation=None) \n",
        "model = ResNet18(in_channels = 28, num_classes= 2)\n",
        "\n",
        "model = model.cuda()\n",
        "\n",
        "# You can also pass Loss.a, Loss.b, Loss.alpha to optimizer (for old version users)\n",
        "loss_fn = AUCMLoss()\n",
        "optimizer = PESG(model, \n",
        "                 loss_fn=loss_fn,\n",
        "                 lr=lr, \n",
        "                 momentum=0.9,\n",
        "                 margin=margin,\n",
        "                 epoch_decay=epoch_decay, \n",
        "                 weight_decay=weight_decay)\n",
        "\n",
        "# model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5cuRVkg7H5P",
        "outputId": "a1eb8082-7fe9-4237-9e37-046a6879b389"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<torch.utils.data.dataloader.DataLoader object at 0x7f8f1b3c4e20>\n"
          ]
        }
      ],
      "source": [
        "print(evalloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "Ann7owgSb_tV",
        "outputId": "9d6fbf4a-8cd1-45c4-98d0-bac2dcee1ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n",
            "------------------------------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-2e6a80509ac5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m               \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m               \u001b[0;31m# val_auc_mean = auc_roc_score(test_true, test_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m               \u001b[0mval_auc_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m               \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_auc_mean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m               \u001b[0;31m# val_auc_mean=val_auc_mean[0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         return _average_binary_score(\n\u001b[0m\u001b[1;32m    573\u001b[0m             \u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_binary_roc_auc_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_fpr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    342\u001b[0m         )\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m     \u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mmax_fpr\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.8\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0;36m0.35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \"\"\"\n\u001b[0;32m--> 992\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m    993\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 753\u001b[0;31m     \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    754\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, dtype, warn)\u001b[0m\n\u001b[1;32m   1200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1202\u001b[0;31m     raise ValueError(\n\u001b[0m\u001b[1;32m   1203\u001b[0m         \u001b[0;34m\"y should be a 1d array, got an array of shape {} instead.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1204\u001b[0m     )\n",
            "\u001b[0;31mValueError\u001b[0m: y should be a 1d array, got an array of shape (382, 2) instead."
          ]
        }
      ],
      "source": [
        "# # training\n",
        "# print ('Start Training')\n",
        "# print ('-'*30)\n",
        "\n",
        "# best_val_auc = 0 \n",
        "# for epoch in range(total_epochs):\n",
        "#     # if epoch % 10 == 0:\n",
        "#     #     optimizer.update_regularizer(decay_factor=2)    \n",
        "\n",
        "#     for idx, (data, targets, _) in enumerate(trainloader):\n",
        "#       train_data, train_labels = data, targets\n",
        "#       train_data, train_labels  = train_data.cuda(), train_labels.cuda()\n",
        "#       y_pred = model(train_data)\n",
        "#       y_pred = torch.sigmoid(y_pred)\n",
        "#       loss = loss_fn(y_pred, train_labels)\n",
        "#       optimizer.zero_grad()\n",
        "#       loss.backward()\n",
        "#       optimizer.step()\n",
        "\n",
        "#       # scheduler1.step(loss)\n",
        "#       # torch.save(model.state_dict(), \"Epoch: {}\".format(epoch))\n",
        "#       # print(\"Saving model for epoch number: {}\".format(epoch))\n",
        "\n",
        "        \n",
        "#       # validation  \n",
        "#       if idx % 20 == 0:\n",
        "#          model.eval()\n",
        "#          with torch.no_grad():    \n",
        "#               test_pred = []\n",
        "#               test_true = [] \n",
        "#               for jdx, (data, targets, _) in enumerate(testloader):\n",
        "#                   test_data, test_labels = data, targets\n",
        "#                   test_data = test_data.cuda()\n",
        "#                   y_pred = model(test_data)\n",
        "#                   y_pred = torch.sigmoid(y_pred)\n",
        "#                   test_pred.append(y_pred.cpu().detach().numpy())\n",
        "#                   test_true.append(test_labels.numpy())\n",
        "            \n",
        "#               test_true = np.concatenate(test_true)\n",
        "#               test_pred = np.concatenate(test_pred)\n",
        "#               # val_auc_mean = auc_roc_score(test_true, test_pred)\n",
        "#               val_auc_mean = roc_auc_score(test_true, test_pred)[0]\n",
        "#               print(val_auc_mean)\n",
        "#               # val_auc_mean=val_auc_mean[0]\n",
        "#               val_auc_mean=val_auc_mean\n",
        "\n",
        "#               model.train()\n",
        "\n",
        "#               if best_val_auc < val_auc_mean:\n",
        "#                  best_val_auc = val_auc_mean\n",
        "#                  torch.save(model.state_dict(), 'vessel_model.pt')\n",
        "\n",
        "#               print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, val_auc_mean, best_val_auc))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print ('Start Training')\n",
        "print ('-'*30)\n",
        "test_best = 0\n",
        "best_val_auc = 0 \n",
        "train_list, test_list = [], []\n",
        "for epoch in range(total_epochs):\n",
        "    #if epoch in decay_epochs:\n",
        "     #   optimizer.update_lr(decay_factor=10, coef_decay_factor=10)\n",
        "            \n",
        "    train_pred, train_true = [], []\n",
        "    model.train() \n",
        "    for idx, (data, targets, index) in enumerate(trainloader):\n",
        "        data, targets  = data.cuda(), targets.cuda()\n",
        "        y_pred = model(data)\n",
        "        y_prob = torch.sigmoid(y_pred)\n",
        "        loss = loss_fn(y_prob, targets) # Notes: make index>0 for positive samples, and index<0 for negative samples\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_pred.append(y_prob.cpu().detach().numpy())\n",
        "        train_true.append(targets.cpu().detach().numpy())\n",
        "\n",
        "    # validation  \n",
        "    model.eval()\n",
        "    with torch.no_grad():    \n",
        "        test_pred = []\n",
        "        test_true = [] \n",
        "        for jdx, data in enumerate(testloader):\n",
        "            test_data, test_labels, index = data\n",
        "            test_data = test_data.cuda()\n",
        "            y_pred = model(test_data)\n",
        "            test_pred.append(y_pred.cpu().detach().numpy())\n",
        "            test_true.append(test_labels.numpy())\n",
        "      \n",
        "        test_true = np.concatenate(test_true)\n",
        "        test_pred = np.concatenate(test_pred)\n",
        "        val_auc_mean =  roc_auc_score(test_true[:,0], test_pred[:,0]) \n",
        "        model.train()\n",
        "\n",
        "        if best_val_auc < val_auc_mean:\n",
        "            best_val_auc = val_auc_mean\n",
        "            torch.save(model.state_dict(), 'ce_pretrained_model.pth')\n",
        "\n",
        "        print ('Epoch=%s, BatchID=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f'%(epoch, idx, val_auc_mean, best_val_auc ))\n",
        "    \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPfrKDGtEjoW",
        "outputId": "9bd03ee7-2f63-4588-b175-16e9fea06dbc"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start Training\n",
            "------------------------------\n",
            "Epoch=0, BatchID=21, Val_AUC=0.8293, Best_Val_AUC=0.8293\n",
            "Epoch=1, BatchID=21, Val_AUC=0.8033, Best_Val_AUC=0.8293\n",
            "Epoch=2, BatchID=21, Val_AUC=0.8263, Best_Val_AUC=0.8293\n",
            "Epoch=3, BatchID=21, Val_AUC=0.8567, Best_Val_AUC=0.8567\n",
            "Epoch=4, BatchID=21, Val_AUC=0.8461, Best_Val_AUC=0.8567\n",
            "Epoch=5, BatchID=21, Val_AUC=0.8638, Best_Val_AUC=0.8638\n",
            "Epoch=6, BatchID=21, Val_AUC=0.8557, Best_Val_AUC=0.8638\n",
            "Epoch=7, BatchID=21, Val_AUC=0.8641, Best_Val_AUC=0.8641\n",
            "Epoch=8, BatchID=21, Val_AUC=0.8749, Best_Val_AUC=0.8749\n",
            "Epoch=9, BatchID=21, Val_AUC=0.8666, Best_Val_AUC=0.8749\n",
            "Epoch=10, BatchID=21, Val_AUC=0.8711, Best_Val_AUC=0.8749\n",
            "Epoch=11, BatchID=21, Val_AUC=0.8725, Best_Val_AUC=0.8749\n",
            "Epoch=12, BatchID=21, Val_AUC=0.8740, Best_Val_AUC=0.8749\n",
            "Epoch=13, BatchID=21, Val_AUC=0.8705, Best_Val_AUC=0.8749\n",
            "Epoch=14, BatchID=21, Val_AUC=0.8732, Best_Val_AUC=0.8749\n",
            "Epoch=15, BatchID=21, Val_AUC=0.8728, Best_Val_AUC=0.8749\n",
            "Epoch=16, BatchID=21, Val_AUC=0.8723, Best_Val_AUC=0.8749\n",
            "Epoch=17, BatchID=21, Val_AUC=0.8712, Best_Val_AUC=0.8749\n",
            "Epoch=18, BatchID=21, Val_AUC=0.8725, Best_Val_AUC=0.8749\n",
            "Epoch=19, BatchID=21, Val_AUC=0.8740, Best_Val_AUC=0.8749\n",
            "Epoch=20, BatchID=21, Val_AUC=0.8764, Best_Val_AUC=0.8764\n",
            "Epoch=21, BatchID=21, Val_AUC=0.8743, Best_Val_AUC=0.8764\n",
            "Epoch=22, BatchID=21, Val_AUC=0.8746, Best_Val_AUC=0.8764\n",
            "Epoch=23, BatchID=21, Val_AUC=0.8736, Best_Val_AUC=0.8764\n",
            "Epoch=24, BatchID=21, Val_AUC=0.8727, Best_Val_AUC=0.8764\n",
            "Epoch=25, BatchID=21, Val_AUC=0.8725, Best_Val_AUC=0.8764\n",
            "Epoch=26, BatchID=21, Val_AUC=0.8736, Best_Val_AUC=0.8764\n",
            "Epoch=27, BatchID=21, Val_AUC=0.8721, Best_Val_AUC=0.8764\n",
            "Epoch=28, BatchID=21, Val_AUC=0.8714, Best_Val_AUC=0.8764\n",
            "Epoch=29, BatchID=21, Val_AUC=0.8727, Best_Val_AUC=0.8764\n",
            "Epoch=30, BatchID=21, Val_AUC=0.8710, Best_Val_AUC=0.8764\n",
            "Epoch=31, BatchID=21, Val_AUC=0.8721, Best_Val_AUC=0.8764\n",
            "Epoch=32, BatchID=21, Val_AUC=0.8703, Best_Val_AUC=0.8764\n",
            "Epoch=33, BatchID=21, Val_AUC=0.8710, Best_Val_AUC=0.8764\n",
            "Epoch=34, BatchID=21, Val_AUC=0.8701, Best_Val_AUC=0.8764\n",
            "Epoch=35, BatchID=21, Val_AUC=0.8701, Best_Val_AUC=0.8764\n",
            "Epoch=36, BatchID=21, Val_AUC=0.8704, Best_Val_AUC=0.8764\n",
            "Epoch=37, BatchID=21, Val_AUC=0.8708, Best_Val_AUC=0.8764\n",
            "Epoch=38, BatchID=21, Val_AUC=0.8701, Best_Val_AUC=0.8764\n",
            "Epoch=39, BatchID=21, Val_AUC=0.8707, Best_Val_AUC=0.8764\n",
            "Epoch=40, BatchID=21, Val_AUC=0.8702, Best_Val_AUC=0.8764\n",
            "Epoch=41, BatchID=21, Val_AUC=0.8709, Best_Val_AUC=0.8764\n",
            "Epoch=42, BatchID=21, Val_AUC=0.8704, Best_Val_AUC=0.8764\n",
            "Epoch=43, BatchID=21, Val_AUC=0.8702, Best_Val_AUC=0.8764\n",
            "Epoch=44, BatchID=21, Val_AUC=0.8692, Best_Val_AUC=0.8764\n",
            "Epoch=45, BatchID=21, Val_AUC=0.8692, Best_Val_AUC=0.8764\n",
            "Epoch=46, BatchID=21, Val_AUC=0.8694, Best_Val_AUC=0.8764\n",
            "Epoch=47, BatchID=21, Val_AUC=0.8697, Best_Val_AUC=0.8764\n",
            "Epoch=48, BatchID=21, Val_AUC=0.8686, Best_Val_AUC=0.8764\n",
            "Epoch=49, BatchID=21, Val_AUC=0.8675, Best_Val_AUC=0.8764\n",
            "Epoch=50, BatchID=21, Val_AUC=0.8663, Best_Val_AUC=0.8764\n",
            "Epoch=51, BatchID=21, Val_AUC=0.8670, Best_Val_AUC=0.8764\n",
            "Epoch=52, BatchID=21, Val_AUC=0.8660, Best_Val_AUC=0.8764\n",
            "Epoch=53, BatchID=21, Val_AUC=0.8653, Best_Val_AUC=0.8764\n",
            "Epoch=54, BatchID=21, Val_AUC=0.8661, Best_Val_AUC=0.8764\n",
            "Epoch=55, BatchID=21, Val_AUC=0.8665, Best_Val_AUC=0.8764\n",
            "Epoch=56, BatchID=21, Val_AUC=0.8645, Best_Val_AUC=0.8764\n",
            "Epoch=57, BatchID=21, Val_AUC=0.8662, Best_Val_AUC=0.8764\n",
            "Epoch=58, BatchID=21, Val_AUC=0.8663, Best_Val_AUC=0.8764\n",
            "Epoch=59, BatchID=21, Val_AUC=0.8674, Best_Val_AUC=0.8764\n",
            "Epoch=60, BatchID=21, Val_AUC=0.8648, Best_Val_AUC=0.8764\n",
            "Epoch=61, BatchID=21, Val_AUC=0.8641, Best_Val_AUC=0.8764\n",
            "Epoch=62, BatchID=21, Val_AUC=0.8638, Best_Val_AUC=0.8764\n",
            "Epoch=63, BatchID=21, Val_AUC=0.8636, Best_Val_AUC=0.8764\n",
            "Epoch=64, BatchID=21, Val_AUC=0.8641, Best_Val_AUC=0.8764\n",
            "Epoch=65, BatchID=21, Val_AUC=0.8638, Best_Val_AUC=0.8764\n",
            "Epoch=66, BatchID=21, Val_AUC=0.8645, Best_Val_AUC=0.8764\n",
            "Epoch=67, BatchID=21, Val_AUC=0.8627, Best_Val_AUC=0.8764\n",
            "Epoch=68, BatchID=21, Val_AUC=0.8634, Best_Val_AUC=0.8764\n",
            "Epoch=69, BatchID=21, Val_AUC=0.8631, Best_Val_AUC=0.8764\n",
            "Epoch=70, BatchID=21, Val_AUC=0.8609, Best_Val_AUC=0.8764\n",
            "Epoch=71, BatchID=21, Val_AUC=0.8596, Best_Val_AUC=0.8764\n",
            "Epoch=72, BatchID=21, Val_AUC=0.8600, Best_Val_AUC=0.8764\n",
            "Epoch=73, BatchID=21, Val_AUC=0.8599, Best_Val_AUC=0.8764\n",
            "Epoch=74, BatchID=21, Val_AUC=0.8607, Best_Val_AUC=0.8764\n",
            "Epoch=75, BatchID=21, Val_AUC=0.8597, Best_Val_AUC=0.8764\n",
            "Epoch=76, BatchID=21, Val_AUC=0.8565, Best_Val_AUC=0.8764\n",
            "Epoch=77, BatchID=21, Val_AUC=0.8578, Best_Val_AUC=0.8764\n",
            "Epoch=78, BatchID=21, Val_AUC=0.8591, Best_Val_AUC=0.8764\n",
            "Epoch=79, BatchID=21, Val_AUC=0.8582, Best_Val_AUC=0.8764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nm7jJYKCiXSU",
        "outputId": "a03c4107-261d-492a-b4bd-b89304db1557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test result   ::::::::   Test_AUC = 0.8764\n"
          ]
        }
      ],
      "source": [
        " # Testing\n",
        " ckpt =  torch.load(\"ce_pretrained_model.pth\")\n",
        " model.load_state_dict(ckpt)\n",
        " model.eval()\n",
        " with torch.no_grad():    \n",
        "      test_pred = []\n",
        "      test_true = [] \n",
        "      for jdx, (data, targets, _) in enumerate(testloader):\n",
        "          test_data, test_labels = data, targets\n",
        "          test_data = test_data.cuda()\n",
        "          y_pred = model(test_data)\n",
        "          y_pred = torch.sigmoid(y_pred)\n",
        "          test_pred.append(y_pred.cpu().detach().numpy())\n",
        "          test_true.append(test_labels.numpy())\n",
        "\n",
        "      test_true = np.concatenate(test_true)\n",
        "      test_pred = np.concatenate(test_pred)\n",
        "      # test_auc_mean = auc_roc_score(test_true, test_pred)[0]\n",
        "      test_auc_mean =  roc_auc_score(test_true[:,0], test_pred[:,0])\n",
        "      model.train()\n",
        "\n",
        "\n",
        "      print ('Test result   ::::::::   Test_AUC = %.4f'%(test_auc_mean))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('ce_pretrained_model.pth')"
      ],
      "metadata": {
        "id": "r7qFq-WbvHc0",
        "outputId": "4f6f11cc-3c50-463a-9513-68607a6b6876",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cccfde21-5d2f-4f31-baba-e2071b387e3c\", \"ce_pretrained_model.pth\", 44816733)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}