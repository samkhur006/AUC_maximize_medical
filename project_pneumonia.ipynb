{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zoB6dFJP9KU4"
      },
      "source": [
        "Pneumonia, Cross entropy, Resnet18, Pretrain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opd2xejtSAGZ",
        "outputId": "ba6a20dd-5b6e-4ab4-a019-bb9bb4972991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting libauc==1.2.0\n",
            "  Downloading libauc-1.2.0-py3-none-any.whl (73 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.6/73.6 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (8.4.0)\n",
            "Requirement already satisfied: torch>=1.2 in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (2.0.0+cu118)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (4.7.0.72)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (0.19.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from libauc==1.2.0) (1.5.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (2.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (3.12.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.2->libauc==1.2.0) (4.5.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2->libauc==1.2.0) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.2->libauc==1.2.0) (16.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc==1.2.0) (2022.7.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (2023.4.12)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (2.25.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (23.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->libauc==1.2.0) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc==1.2.0) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->libauc==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.2->libauc==1.2.0) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.2->libauc==1.2.0) (1.3.0)\n",
            "Installing collected packages: libauc\n",
            "Successfully installed libauc-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting medmnist\n",
            "  Downloading medmnist-2.2.1-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.5.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.15.1+cu118)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from medmnist) (2.0.0+cu118)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from medmnist) (0.19.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from medmnist) (4.65.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from medmnist) (1.22.4)\n",
            "Collecting fire\n",
            "  Downloading fire-0.5.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.3/88.3 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from medmnist) (8.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->medmnist) (2.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->medmnist) (2022.7.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (2023.4.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (23.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (3.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.10.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->medmnist) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->medmnist) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.12.0)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (2.0.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->medmnist) (4.5.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (16.0.2)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch->medmnist) (3.25.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->medmnist) (2.27.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->medmnist) (2.1.2)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->medmnist) (1.26.15)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->medmnist) (1.3.0)\n",
            "Building wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.5.0-py2.py3-none-any.whl size=116952 sha256=57b8528f90dd463e248242d3f6906806e9e4c7aac95b5dc0e6f7a441ea5b33cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/d4/f7/9404e5db0116bd4d43e5666eaa3e70ab53723e1e3ea40c9a95\n",
            "Successfully built fire\n",
            "Installing collected packages: fire, medmnist\n",
            "Successfully installed fire-0.5.0 medmnist-2.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install libauc==1.2.0\n",
        "!pip install medmnist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "6wdjTJFtNb8k"
      },
      "outputs": [],
      "source": [
        "import libauc;\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from medmnist import PneumoniaMNIST, NoduleMNIST3D\n",
        "from libauc.models import resnet18\n",
        "from libauc.datasets import CIFAR10\n",
        "from libauc.losses.auc import pAUCLoss  # default: SOPA\n",
        "from libauc.losses.auc import pAUC_CVaR_Loss\n",
        "from libauc.optimizers import SOPA\n",
        "from libauc.utils import ImbalancedDataGenerator\n",
        "from libauc.sampler import DualSampler  # data resampling (for binary class)\n",
        "from libauc.metrics import auc_roc_score\n",
        "from libauc.losses import AUCMLoss, CrossEntropyLoss\n",
        "from libauc.optimizers import PESG, Adam\n",
        "import random\n",
        "import scipy\n",
        "from scipy.ndimage import rotate\n",
        "from torch.optim.lr_scheduler import ReduceLROnPlateau, CosineAnnealingLR\n",
        "from scipy import ndimage\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from scipy.ndimage import zoom\n",
        "\n",
        "\n",
        "import torch \n",
        "from PIL import Image\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "SEED=123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KpFaiTXwSQ5D"
      },
      "outputs": [],
      "source": [
        "def set_all_seeds(SEED):\n",
        "    # REPRODUCIBILITY\n",
        "    torch.manual_seed(SEED)\n",
        "    np.random.seed(SEED)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "oFSCnba3SSS0"
      },
      "outputs": [],
      "source": [
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, images, targets, image_size=28, crop_size=26, mode='train'):\n",
        "       self.images = images.astype(np.uint8)\n",
        "       self.targets = targets\n",
        "       self.mode = mode\n",
        "       self.transform_train = transforms.Compose([ \n",
        "                              transforms.Grayscale(num_output_channels=3),                                               \n",
        "                              transforms.ToTensor(),\n",
        "                              transforms.RandomCrop((crop_size, crop_size), padding=None),\n",
        "                              transforms.RandomHorizontalFlip(),\n",
        "                              transforms.Resize((image_size, image_size)),\n",
        "                              ])\n",
        "       self.transform_test = transforms.Compose([\n",
        "                              transforms.Grayscale(num_output_channels=3),  \n",
        "                             transforms.ToTensor(),\n",
        "                             transforms.Resize((image_size, image_size)),\n",
        "                              ])\n",
        "       \n",
        "       # for loss function\n",
        "       self.pos_indices = np.flatnonzero(targets==1)\n",
        "       self.pos_index_map = {}\n",
        "       for i, idx in enumerate(self.pos_indices):\n",
        "           self.pos_index_map[idx] = i\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        target = self.targets[idx]\n",
        "        image = Image.fromarray(image.astype('uint8'))\n",
        "        if self.mode == 'train':\n",
        "            idx = self.pos_index_map[idx] if idx in self.pos_indices else -1\n",
        "            image = self.transform_train(image)\n",
        "        else:\n",
        "            image = self.transform_test(image)\n",
        "        return image, target, int(idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Wrax-3nWSZJ-"
      },
      "outputs": [],
      "source": [
        "# general params\n",
        "\n",
        "weight_decay = 5e-4\n",
        "total_epoch = 60\n",
        "decay_epochs = [20, 40]\n",
        "batch_size = 64\n",
        "\n",
        "# sampling parameters\n",
        "sampling_rate = 0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihmqlVmDcL0l",
        "outputId": "27341227-97e2-449f-d351-c313ece1cd81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://zenodo.org/record/6496656/files/pneumoniamnist.npz?download=1 to /root/.medmnist/pneumoniamnist.npz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4170669/4170669 [00:13<00:00, 304566.57it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\n",
            "Using downloaded and verified file: /root/.medmnist/pneumoniamnist.npz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "train_npz=PneumoniaMNIST(split=\"train\", download=True)\n",
        "val_npz=PneumoniaMNIST(split=\"val\", download=True)\n",
        "test_npz=PneumoniaMNIST(split=\"test\", download=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "CKhWfPSzBJ1J"
      },
      "outputs": [],
      "source": [
        "def gaussian_blur_2d(img):\n",
        "    random.seed(SEED)\n",
        "    sigma = random.uniform(0.1,0.9)\n",
        "    blurred = gaussian_filter(img, sigma=sigma)\n",
        "    return blurred\n",
        "\n",
        "def x_flip(img):\n",
        "    random.seed(SEED)\n",
        "    flipped = np.flipud(img)\n",
        "    return flipped\n",
        "\n",
        "def y_flip(img):\n",
        "    random.seed(SEED)\n",
        "    flipped = np.flip(img,axis=1)\n",
        "    return flipped\n",
        "\n",
        "def zoom_xy(img, min_zoom, max_zoom):\n",
        "    random.seed(SEED)\n",
        "    zoom_factor = random.uniform(min_zoom, max_zoom)\n",
        "    new_shape = (int(img.shape[0] * zoom_factor), int(img.shape[1] * zoom_factor))\n",
        "\n",
        "    # Zoom in on the image using scipy.ndimage.zoom()\n",
        "    zoomed_img = rotate(img, zoom_factor, reshape=False)\n",
        "\n",
        "    # Crop the zoomed image to the original dimensions\n",
        "    crop_x = int((zoomed_img.shape[1] - img.shape[1]) / 2)\n",
        "    crop_y = int((zoomed_img.shape[0] - img.shape[0]) / 2)\n",
        "    zoomed_img = zoomed_img[crop_y:crop_y+img.shape[0], crop_x:crop_x+img.shape[1]]\n",
        "\n",
        "    return zoomed_img\n",
        "\n",
        "def random_rotation_2d(img, min_angle, max_angle):\n",
        "    \"\"\" Randomly rotate an image by a random angle (-max_angle, max_angle).\n",
        "\n",
        "    Arguments:\n",
        "    max_angle: `float`. The maximum rotation angle.\n",
        "\n",
        "    Returns:\n",
        "    rotated 3D image\n",
        "    \"\"\"\n",
        "    random.seed(SEED)\n",
        "    img_rot = np.zeros(img.shape)\n",
        "    angle = random.uniform(min_angle, max_angle)\n",
        "    if random.randint(1,100) > 50:\n",
        "        #in half the cases, rotate left. in other half, rotate right.\n",
        "        angle *= -1\n",
        "        # Following lines would rotate on z and y axis as well, but not using them in this kernel\n",
        "#        # rotate along z-axis\n",
        "#        image2 = scipy.ndimage.interpolation.rotate(image1, angle, mode='nearest', axes=(0, 1), reshape=False)\n",
        "#        # rotate along y-axis\n",
        "#        image3 = scipy.ndimage.interpolation.rotate(image2, angle, mode='nearest', axes=(0, 2), reshape=False)\n",
        "\n",
        "    # rotate along x-axis\n",
        "    img_rot = ndimage.rotate(img, angle, reshape=False)\n",
        "    return img_rot.reshape(img.shape)\n",
        "\n",
        "def img_augment_2d(X_train,y_train):\n",
        "      my_img=X_train\n",
        "      my_label=y_train\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = gaussian_blur_2d(img)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "      print(\"blur done \")\n",
        "      # for i in range(0,X_train.shape[0]):\n",
        "      #   img=X_train[i]\n",
        "      #   img1 = x_flip(img)\n",
        "      #   my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      # my_label=np.append(my_label,y_train,axis=0)\n",
        "      # print(\"flip done \")\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = y_flip(img)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "      print(\"flip2 done \")\n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = random_rotation_2d(img, 1, 10)\n",
        "        my_img=np.append(my_img,np.expand_dims(img1,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "      print(\"rotation done \")\n",
        "      # for i in range(0,X_train.shape[0]):\n",
        "      #   img=X_train[i]\n",
        "      #   img1 = random_rotation_2d(img, 1, 10)\n",
        "      #   img2=  zoom_xy(img, 0.9, 1.1)\n",
        "      #   img3 = y_flip(img2)\n",
        "      #   my_img=np.append(my_img,np.expand_dims(img3,axis=0),axis=0)\n",
        "      # my_label=np.append(my_label,y_train,axis=0)\n",
        "    \n",
        "      for i in range(0,X_train.shape[0]):\n",
        "        img=X_train[i]\n",
        "        img1 = zoom_xy(img, 0.9, 1.1)\n",
        "        img2=x_flip(img1)\n",
        "        my_img=np.append(my_img,np.expand_dims(img2,axis=0),axis=0)\n",
        "      my_label=np.append(my_label,y_train,axis=0)\n",
        "    \n",
        "      return my_img,my_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {
        "id": "-ZUWj_z0Dpxb"
      },
      "outputs": [],
      "source": [
        "X_train=train_npz.imgs\n",
        "y_train=train_npz.labels\n",
        "\n",
        "X_val=val_npz.imgs\n",
        "y_val=val_npz.labels\n",
        "\n",
        "X_test=test_npz.imgs\n",
        "y_test=test_npz.labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49mraZctJo59",
        "outputId": "26e9aa43-6c97-44d6-d6c5-28025af6aa82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4316, 28, 28)\n",
            "(4316, 1)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXmsX3BLjZPg",
        "outputId": "2079a3c5-ccc6-4914-f4e5-5db6e93109e5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4707, 1)"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.delete(y_train,1,axis=0).shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4X8418nBMvi",
        "outputId": "c159b770-e76b-4a03-efae-495a0c2e9ed4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "blur done \n",
            "flip2 done \n",
            "rotation done \n"
          ]
        }
      ],
      "source": [
        "X_train,y_train=img_augment_2d(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "id": "BOvwPFsIix4M"
      },
      "outputs": [],
      "source": [
        "random.seed(SEED)\n",
        "for i in range(1,2000):\n",
        "  idx=random.randint(0,X_train.shape[0])\n",
        "  if y_train[idx]==1:\n",
        "    coin_toss=random.randint(1,100)\n",
        "    if coin_toss<=50:\n",
        "      X_train=np.delete(X_train,idx,axis=0)\n",
        "      y_train=np.delete(y_train,1,axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjzSOJF-WtVC",
        "outputId": "55018b4d-d4b0-41a1-aa4a-ab128ef77afe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#SAMPLES: [1843], POS:NEG: [921 : 922], POS RATIO: 0.4997\n",
            "#SAMPLES: [269], POS:NEG: [134 : 135], POS RATIO: 0.4981\n",
            "#SAMPLES: [624], POS:NEG: [390 : 234], POS RATIO: 0.6250\n"
          ]
        }
      ],
      "source": [
        "imratio = 0.4999\n",
        "generator = ImbalancedDataGenerator(shuffle=True, verbose=True)#, random_seed=3)\n",
        "(train_images, train_labels) = generator.transform(X_train, y_train, imratio=imratio)\n",
        "(eval_images, eval_labels) = generator.transform(X_val, y_val, imratio=imratio)\n",
        "(test_images, test_labels) = generator.transform(X_test, y_test, imratio=0.5) \n",
        "\n",
        "trainSet = ImageDataset(train_images, train_labels)\n",
        "evalSet = ImageDataset(eval_images, eval_labels)\n",
        "testSet = ImageDataset(test_images, test_labels, mode='test')\n",
        "\n",
        "sampler = DualSampler(trainSet, batch_size, sampling_rate=sampling_rate)\n",
        "trainloader = torch.utils.data.DataLoader(trainSet, batch_size=batch_size,  sampler=sampler,  shuffle=False,  num_workers=1)\n",
        "evalloader = torch.utils.data.DataLoader(evalSet, batch_size=batch_size,  shuffle=False,  num_workers=1)\n",
        "testloader = torch.utils.data.DataLoader(testSet , batch_size=batch_size, shuffle=False, num_workers=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {
        "id": "GV8dknfBbXnC"
      },
      "outputs": [],
      "source": [
        "# paramaters\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "weight_decay = 1e-5\n",
        "\n",
        "# model\n",
        "lr=0.001\n",
        "set_all_seeds(SEED)\n",
        "model = resnet18(pretrained=False, num_classes=1, last_activation=None) \n",
        "model = model.cuda()\n",
        "\n",
        "# define loss & optimizer\n",
        "loss_fn = AUCMLoss()\n",
        "optimizer = Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "\n",
        "scheduler1 =  ReduceLROnPlateau(optimizer, 'min', patience=2, factor = 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sBjmsLwWEeB",
        "outputId": "cad2cf41-6323-4b4c-b33d-ffbf7829dcbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Start Training\n",
            "------------------------------\n",
            "Epoch=0, Val_AUC=0.6046, Best_Val_AUC=0.6046, lr: 0.0010\n",
            "     Test result test_AUC=0.4720\n",
            "Epoch=1, Val_AUC=0.3076, Best_Val_AUC=0.6046, lr: 0.0010\n",
            "     Test result test_AUC=0.3947\n",
            "Epoch=2, Val_AUC=0.5066, Best_Val_AUC=0.6046, lr: 0.0010\n",
            "     Test result test_AUC=0.7081\n",
            "Epoch=3, Val_AUC=0.5583, Best_Val_AUC=0.6046, lr: 0.0010\n",
            "     Test result test_AUC=0.7208\n",
            "Epoch=4, Val_AUC=0.5863, Best_Val_AUC=0.6046, lr: 0.0010\n",
            "     Test result test_AUC=0.7350\n",
            "Epoch=5, Val_AUC=0.5922, Best_Val_AUC=0.6046, lr: 0.0010\n",
            "     Test result test_AUC=0.7313\n",
            "Epoch=6, Val_AUC=0.6020, Best_Val_AUC=0.6046, lr: 0.0010\n",
            "     Test result test_AUC=0.7290\n",
            "Epoch=7, Val_AUC=0.6341, Best_Val_AUC=0.6341, lr: 0.0010\n",
            "     Test result test_AUC=0.7394\n",
            "Epoch=8, Val_AUC=0.6291, Best_Val_AUC=0.6341, lr: 0.0010\n",
            "     Test result test_AUC=0.7223\n",
            "Epoch=9, Val_AUC=0.6065, Best_Val_AUC=0.6341, lr: 0.0010\n",
            "     Test result test_AUC=0.7368\n",
            "Epoch=10, Val_AUC=0.6482, Best_Val_AUC=0.6482, lr: 0.0010\n",
            "     Test result test_AUC=0.7499\n",
            "Epoch=11, Val_AUC=0.6617, Best_Val_AUC=0.6617, lr: 0.0010\n",
            "     Test result test_AUC=0.7453\n",
            "Epoch=12, Val_AUC=0.6398, Best_Val_AUC=0.6617, lr: 0.0010\n",
            "     Test result test_AUC=0.7599\n",
            "Epoch=13, Val_AUC=0.5986, Best_Val_AUC=0.6617, lr: 0.0010\n",
            "     Test result test_AUC=0.7438\n",
            "Epoch=14, Val_AUC=0.5685, Best_Val_AUC=0.6617, lr: 0.0010\n",
            "     Test result test_AUC=0.7334\n",
            "Epoch=15, Val_AUC=0.6205, Best_Val_AUC=0.6617, lr: 0.0010\n",
            "     Test result test_AUC=0.7580\n",
            "Epoch=16, Val_AUC=0.6374, Best_Val_AUC=0.6617, lr: 0.0010\n",
            "     Test result test_AUC=0.7609\n",
            "Epoch=17, Val_AUC=0.6531, Best_Val_AUC=0.6617, lr: 0.0010\n",
            "     Test result test_AUC=0.7744\n",
            "Epoch=18, Val_AUC=0.6169, Best_Val_AUC=0.6617, lr: 0.0010\n",
            "     Test result test_AUC=0.7511\n",
            "Epoch=19, Val_AUC=0.6592, Best_Val_AUC=0.6617, lr: 0.0001\n",
            "     Test result test_AUC=0.7880\n",
            "Reducing learning rate to 0.00001 !\n",
            "Epoch=20, Val_AUC=0.6888, Best_Val_AUC=0.6888, lr: 0.0000\n",
            "     Test result test_AUC=0.7821\n",
            "Epoch=21, Val_AUC=0.6424, Best_Val_AUC=0.6888, lr: 0.0000\n",
            "     Test result test_AUC=0.7594\n",
            "Epoch=22, Val_AUC=0.6331, Best_Val_AUC=0.6888, lr: 0.0000\n",
            "     Test result test_AUC=0.7603\n",
            "Epoch=23, Val_AUC=0.6380, Best_Val_AUC=0.6888, lr: 0.0000\n",
            "     Test result test_AUC=0.7834\n",
            "Epoch=24, Val_AUC=0.6413, Best_Val_AUC=0.6888, lr: 0.0000\n",
            "     Test result test_AUC=0.7708\n",
            "Epoch=25, Val_AUC=0.7159, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7922\n",
            "Epoch=26, Val_AUC=0.6500, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7748\n",
            "Epoch=27, Val_AUC=0.6468, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7712\n",
            "Epoch=28, Val_AUC=0.6022, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7708\n",
            "Epoch=29, Val_AUC=0.6792, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7791\n",
            "Epoch=30, Val_AUC=0.6258, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7513\n",
            "Epoch=31, Val_AUC=0.6324, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7718\n",
            "Epoch=32, Val_AUC=0.5605, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7582\n",
            "Epoch=33, Val_AUC=0.6386, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7602\n",
            "Epoch=34, Val_AUC=0.6220, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7689\n",
            "Epoch=35, Val_AUC=0.6004, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7531\n",
            "Epoch=36, Val_AUC=0.6257, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7685\n",
            "Epoch=37, Val_AUC=0.6900, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7847\n",
            "Epoch=38, Val_AUC=0.6582, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7735\n",
            "Epoch=39, Val_AUC=0.6035, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7725\n",
            "Reducing learning rate to 0.00000 !\n",
            "Epoch=40, Val_AUC=0.6583, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7802\n",
            "Epoch=41, Val_AUC=0.6441, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7806\n",
            "Epoch=42, Val_AUC=0.6725, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7823\n",
            "Epoch=43, Val_AUC=0.6515, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7559\n",
            "Epoch=44, Val_AUC=0.6583, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7714\n",
            "Epoch=45, Val_AUC=0.6306, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7723\n",
            "Epoch=46, Val_AUC=0.6771, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7702\n",
            "Epoch=47, Val_AUC=0.6663, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7795\n",
            "Epoch=48, Val_AUC=0.6751, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7833\n",
            "Epoch=49, Val_AUC=0.6211, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7536\n",
            "Epoch=50, Val_AUC=0.6227, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7806\n",
            "Epoch=51, Val_AUC=0.6362, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7781\n",
            "Epoch=52, Val_AUC=0.6398, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7720\n",
            "Epoch=53, Val_AUC=0.6244, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7769\n",
            "Epoch=54, Val_AUC=0.6504, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7798\n",
            "Epoch=55, Val_AUC=0.6258, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7811\n",
            "Epoch=56, Val_AUC=0.6260, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7605\n",
            "Epoch=57, Val_AUC=0.6530, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7792\n",
            "Epoch=58, Val_AUC=0.6191, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7711\n",
            "Epoch=59, Val_AUC=0.6693, Best_Val_AUC=0.7159, lr: 0.0000\n",
            "     Test result test_AUC=0.7713\n"
          ]
        }
      ],
      "source": [
        "print ('Start Training')\n",
        "print ('-'*30)\n",
        "# ckpt =  torch.load(\"pneumonia_model.pt\")\n",
        "# model.load_state_dict(ckpt)\n",
        "test_best = 0\n",
        "best_train_auc = 0 \n",
        "train_list, test_list = [], []\n",
        "for epoch in range(total_epoch):\n",
        "    if epoch in decay_epochs:\n",
        "       optimizer.update_lr(decay_factor=10)\n",
        "            \n",
        "    train_pred, train_true = [], []\n",
        "    train_loss = []\n",
        "    model.train() \n",
        "    for idx, (data, targets, index) in enumerate(trainloader):\n",
        "        data, targets  = data.cuda(), targets.cuda()\n",
        "        y_pred = model(data)\n",
        "        y_prob = torch.sigmoid(y_pred)\n",
        "        loss = loss_fn(y_prob, targets) # Notes: make index>0 for positive samples, and index<0 for negative samples\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss.append(loss.item())\n",
        "        train_pred.append(y_prob.cpu().detach().numpy())\n",
        "        train_true.append(targets.cpu().detach().numpy())\n",
        "    train_loss = np.mean(train_loss)\n",
        "    scheduler1.step(train_loss)\n",
        "    # validation  \n",
        "    model.eval()\n",
        "    with torch.no_grad():    \n",
        "        test_pred = []\n",
        "        test_true = [] \n",
        "        for jdx, data in enumerate(evalloader):\n",
        "            test_data, test_labels, index = data\n",
        "            test_data = test_data.cuda()\n",
        "            y_pred = model(test_data)\n",
        "            test_pred.append(y_pred.cpu().detach().numpy())\n",
        "            test_true.append(test_labels.numpy())\n",
        "      \n",
        "        test_true = np.concatenate(test_true)\n",
        "        test_pred = np.concatenate(test_pred)\n",
        "        train_auc_mean =  auc_roc_score(test_true, test_pred) \n",
        "\n",
        "\n",
        "        if best_train_auc < train_auc_mean:\n",
        "            best_train_auc = train_auc_mean\n",
        "            torch.save(model.state_dict(), 'pneumonia_model2.pt')\n",
        "\n",
        "        print ('Epoch=%s, Val_AUC=%.4f, Best_Val_AUC=%.4f, lr: %.4f'%(epoch, train_auc_mean, best_train_auc ,optimizer.lr))\n",
        "  \n",
        "    # Testing\n",
        "\n",
        "    with torch.no_grad():    \n",
        "        test_pred = []\n",
        "        test_true = [] \n",
        "        for jdx, (data, targets, _) in enumerate(testloader):\n",
        "            test_data, test_labels = data, targets\n",
        "            test_data = test_data.cuda()\n",
        "            y_pred = model(test_data)\n",
        "            y_pred = torch.sigmoid(y_pred)\n",
        "            test_pred.append(y_pred.cpu().detach().numpy())\n",
        "            test_true.append(test_labels.numpy())\n",
        "        test_true = np.concatenate(test_true)\n",
        "        test_pred = np.concatenate(test_pred)\n",
        "        test_auc_mean = auc_roc_score(test_true, test_pred)\n",
        "\n",
        "        print ('     Test result test_AUC=%.4f'%(test_auc_mean))\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wANsR0LNwjrh",
        "outputId": "f06fad35-cac5-4e3b-f5b3-b1e49d57d57f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test result :::::::::  Test_AUC=0.7951, Best_train_AUC=0.7159\n"
          ]
        }
      ],
      "source": [
        "# Testing\n",
        "ckpt =  torch.load(\"pneumonia_model.pt\")\n",
        "model.load_state_dict(ckpt)\n",
        "model.eval()\n",
        "best_val_auc = 0\n",
        "with torch.no_grad():    \n",
        "    test_pred = []\n",
        "    test_true = [] \n",
        "    for jdx, (data, targets, _) in enumerate(testloader):\n",
        "        test_data, test_labels = data, targets\n",
        "        test_data = test_data.cuda()\n",
        "        y_pred = model(test_data)\n",
        "        y_pred = torch.sigmoid(y_pred)\n",
        "        test_pred.append(y_pred.cpu().detach().numpy())\n",
        "        test_true.append(test_labels.numpy())\n",
        "\n",
        "    test_true = np.concatenate(test_true)\n",
        "    test_pred = np.concatenate(test_pred)\n",
        "    test_auc_mean = auc_roc_score(test_true, test_pred) \n",
        "\n",
        "    print ('Test result :::::::::  Test_AUC=%.4f, Best_train_AUC=%.4f'%(test_auc_mean, best_train_auc))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
